{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_car.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDhp6GduW6_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/__MACOSX"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTFIvf8gegco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/cars_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCG_Qn0jwjWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \"/content/cars_data.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V45IQKP9dtGN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder = \"/content/cars_data\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRdMfirE7Gbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r samples.zip /content/samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Be6u3UPZj4oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r car_data_new.zip /content/cars_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm2hdmLYkEbi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "2af8597f-cd09-4eee-e400-038ba4baf9e1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/4AHt9-CHATSIsVJ7PqJoulIhL_l6O2wBgdoUF48vsL7ExxInjdJVmFQ\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPClChvDkXMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/car_data_new.zip /content/drive/'My Drive'"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCmA8DoV7X1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/samples"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7fPVRRVstV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQsJ0rwRtwd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4--YlgBuE7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import datetime\n",
        "import os, sys"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13lQ2Xm1uIac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "from matplotlib.pyplot import imshow, imsave\n",
        "%matplotlib inline\n",
        "MODEL_NAME = 'DCGAN'\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMasXRkh7fTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder = \"/content/cars_data\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q31UVSDtxWNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for filename in os.listdir(folder):\n",
        "    img = Image.open(os.path.join(folder,filename)).convert('RGB')\n",
        "    img.save(os.path.join(folder,filename)) \n",
        "    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPb-Sy65uKoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_DIM = (32, 32, 3)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQvkWRKXunEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sample_image(G, n_noise):\n",
        "    \"\"\"\n",
        "        save sample 100 images\n",
        "    \"\"\"\n",
        "    z = torch.randn(10, n_noise).to(DEVICE)\n",
        "    y_hat = G(z).view(10, 3, 32, 32).permute(0, 2, 3, 1) # (100, 28, 28)\n",
        "    result = (y_hat.detach().cpu().numpy()+1)/2.\n",
        "    return result"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZqgREMlupqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "        Convolutional Discriminator for MNIST\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channel=1, num_classes=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            # 28 -> 14\n",
        "            nn.Conv2d(in_channel, 512, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # 14 -> 7\n",
        "            nn.Conv2d(512, 256, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # 7 -> 4\n",
        "            nn.Conv2d(256, 128, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # \n",
        "            nn.Conv2d(128, 128, 3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "        )        \n",
        "        self.fc = nn.Sequential(\n",
        "            # reshape input, 128 -> 1\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "    \n",
        "    def forward(self, x, y=None):\n",
        "        y_ = self.conv(x)\n",
        "        y_ = y_.view(y_.size(0), -1)\n",
        "        y_ = self.fc(y_)\n",
        "        return y_"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DP6PTHpuqu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "        Convolutional Generator for MNIST\n",
        "    \"\"\"\n",
        "    def __init__(self, out_channel=1, input_size=100, num_classes=784):\n",
        "        super(Generator, self).__init__()\n",
        "        assert IMAGE_DIM[0] % 2**4 == 0, 'Should be divided 16'\n",
        "        self.init_dim = (IMAGE_DIM[0] // 2**4, IMAGE_DIM[1] // 2**4)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(input_size, self.init_dim[0]*self.init_dim[1]*512),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, 3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            # x2\n",
        "            nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            # x2\n",
        "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            # x2\n",
        "            nn.ConvTranspose2d(128, 128, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            # x2\n",
        "            nn.ConvTranspose2d(128, out_channel, 4, stride=2, padding=1, bias=False),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x, y=None):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        y_ = self.fc(x)\n",
        "        y_ = y_.view(y_.size(0), 512, self.init_dim[0], self.init_dim[1])\n",
        "        y_ = self.conv(y_)\n",
        "        return y_"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylF-9NqTvKdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CARS(Dataset):\n",
        "    '''\n",
        "    CARS Dataset\n",
        "    You should download this dataset from below url.\n",
        "    url: https://ai.stanford.edu/~jkrause/cars/car_dataset.html\n",
        "    '''\n",
        "    def __init__(self, data_path, transform=None):\n",
        "        '''\n",
        "        Args:\n",
        "            data_path (str): path to dataset\n",
        "        '''\n",
        "        self.data_path = data_path\n",
        "        self.transform = transform\n",
        "        self.fpaths = sorted(glob.glob(os.path.join(data_path, '*.jpeg')))\n",
        "        #gray_lst = [266, 1085, 2176, 3048, 3439, 3469, 3539, 4577, 4848, 5177, 5502, 5713, 6947, 7383, 7693, 7774, 8137, 8144]\n",
        "        #for num in gray_lst:\n",
        "        #    self.fpaths.remove(os.path.join(data_path, '{:05d}.png'.format(num)))\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        img = self.transform(Image.open(self.fpaths[idx]))\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.fpaths)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYra8KvnvM1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D = Discriminator(in_channel=IMAGE_DIM[-1]).to(DEVICE)\n",
        "G = Generator(out_channel=IMAGE_DIM[-1]).to(DEVICE)\n",
        "# D.load_state_dict('D_dc.pkl')\n",
        "# G.load_state_dict('G_dc.pkl')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhVPnDU1vO_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "transform = transforms.Compose([transforms.Resize((IMAGE_DIM[0],IMAGE_DIM[1])),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=(0.5, 0.5, 0.5),\n",
        "                                std=(0.5, 0.5, 0.5))\n",
        "                               ]\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_pQB-ZFvUnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = CARS(data_path='/content/cars_data/', transform=transform)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX7AZvDMvWds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y23w-XTFvXFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=8)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUxFV7Wbvbyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "D_opt = torch.optim.Adam(D.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
        "G_opt = torch.optim.Adam(G.parameters(), lr=0.001, betas=(0.5, 0.999))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqhjuXdcvdVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_epoch = 2200\n",
        "step = 0\n",
        "n_critic = 1 # for training more k steps about Discriminator\n",
        "n_noise = 100"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FOT9WiGvflg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "D_labels = torch.ones([batch_size, 1]).to(DEVICE) # Discriminator Label to real\n",
        "D_fakes = torch.zeros([batch_size, 1]).to(DEVICE) # Discriminator Label to fake"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XnIzTJDyM7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir samples"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gry7j7v4vjxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "5de5d911-98a1-427c-ef73-f8a69240a5ae"
      },
      "source": [
        "for epoch in range(max_epoch):\n",
        "    for idx, images in enumerate(data_loader):\n",
        "        # Training Discriminator\n",
        "        x = images.to(DEVICE)\n",
        "        x_outputs = D(x)\n",
        "        D_x_loss = criterion(x_outputs, D_labels)\n",
        "\n",
        "        z = torch.randn(batch_size, n_noise).to(DEVICE)\n",
        "        z_outputs = D(G(z))\n",
        "        D_z_loss = criterion(z_outputs, D_fakes)\n",
        "        D_loss = D_x_loss + D_z_loss\n",
        "        \n",
        "        D.zero_grad()\n",
        "        D_loss.backward()\n",
        "        D_opt.step()\n",
        "\n",
        "        if step % n_critic == 0:\n",
        "            # Training Generator\n",
        "            z = torch.randn(batch_size, n_noise).to(DEVICE)\n",
        "            z_outputs = D(G(z))\n",
        "            G_loss = criterion(z_outputs, D_labels)\n",
        "\n",
        "            D.zero_grad()\n",
        "            G.zero_grad()\n",
        "            G_loss.backward()\n",
        "            G_opt.step()\n",
        "        \n",
        "        if step % 500 == 0:\n",
        "            dt = datetime.datetime.now().strftime('%H:%M:%S')\n",
        "            print('Epoch: {}/{}, Step: {}, D Loss: {:.4f}, G Loss: {:.4f}, Time:{}'.format(epoch, max_epoch, step, D_loss.item(), G_loss.item(), dt))\n",
        "            G.eval()\n",
        "            img = get_sample_image(G, n_noise)\n",
        "            imsave('samples/{}_step{:05d}.jpg'.format(MODEL_NAME, step), img[0])\n",
        "            G.train()\n",
        "        step += 1"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0/2200, Step: 0, D Loss: 1.3951, G Loss: 0.7163, Time:18:38:10\n",
            "Epoch: 55/2200, Step: 500, D Loss: 0.8883, G Loss: 1.5214, Time:18:39:38\n",
            "Epoch: 111/2200, Step: 1000, D Loss: 0.7377, G Loss: 2.2642, Time:18:41:08\n",
            "Epoch: 166/2200, Step: 1500, D Loss: 0.4964, G Loss: 3.1451, Time:18:42:37\n",
            "Epoch: 222/2200, Step: 2000, D Loss: 0.3691, G Loss: 3.3335, Time:18:44:07\n",
            "Epoch: 277/2200, Step: 2500, D Loss: 0.3819, G Loss: 5.1033, Time:18:45:37\n",
            "Epoch: 333/2200, Step: 3000, D Loss: 0.0846, G Loss: 3.6961, Time:18:47:07\n",
            "Epoch: 388/2200, Step: 3500, D Loss: 0.1358, G Loss: 4.9617, Time:18:48:38\n",
            "Epoch: 444/2200, Step: 4000, D Loss: 0.2558, G Loss: 4.5639, Time:18:50:10\n",
            "Epoch: 500/2200, Step: 4500, D Loss: 0.0799, G Loss: 6.1399, Time:18:51:42\n",
            "Epoch: 555/2200, Step: 5000, D Loss: 0.2742, G Loss: 6.5838, Time:18:53:13\n",
            "Epoch: 611/2200, Step: 5500, D Loss: 0.0364, G Loss: 5.6401, Time:18:54:45\n",
            "Epoch: 666/2200, Step: 6000, D Loss: 0.2710, G Loss: 6.2030, Time:18:56:14\n",
            "Epoch: 722/2200, Step: 6500, D Loss: 0.0211, G Loss: 7.4787, Time:18:57:44\n",
            "Epoch: 777/2200, Step: 7000, D Loss: 0.0043, G Loss: 8.3666, Time:18:59:13\n",
            "Epoch: 833/2200, Step: 7500, D Loss: 0.0016, G Loss: 13.5679, Time:19:00:43\n",
            "Epoch: 888/2200, Step: 8000, D Loss: 0.0090, G Loss: 6.2731, Time:19:02:12\n",
            "Epoch: 944/2200, Step: 8500, D Loss: 0.0823, G Loss: 5.6940, Time:19:03:42\n",
            "Epoch: 1000/2200, Step: 9000, D Loss: 0.0503, G Loss: 7.8435, Time:19:05:12\n",
            "Epoch: 1055/2200, Step: 9500, D Loss: 0.0530, G Loss: 5.7395, Time:19:06:42\n",
            "Epoch: 1111/2200, Step: 10000, D Loss: 0.0295, G Loss: 7.7425, Time:19:08:15\n",
            "Epoch: 1166/2200, Step: 10500, D Loss: 0.0426, G Loss: 5.3060, Time:19:09:45\n",
            "Epoch: 1222/2200, Step: 11000, D Loss: 0.0350, G Loss: 4.9802, Time:19:11:16\n",
            "Epoch: 1277/2200, Step: 11500, D Loss: 0.0123, G Loss: 6.8195, Time:19:12:45\n",
            "Epoch: 1333/2200, Step: 12000, D Loss: 0.2481, G Loss: 6.0285, Time:19:14:15\n",
            "Epoch: 1388/2200, Step: 12500, D Loss: 0.0366, G Loss: 5.2994, Time:19:15:43\n",
            "Epoch: 1444/2200, Step: 13000, D Loss: 0.0297, G Loss: 4.9472, Time:19:17:13\n",
            "Epoch: 1500/2200, Step: 13500, D Loss: 0.0480, G Loss: 4.6829, Time:19:18:43\n",
            "Epoch: 1555/2200, Step: 14000, D Loss: 0.1499, G Loss: 9.7407, Time:19:20:11\n",
            "Epoch: 1611/2200, Step: 14500, D Loss: 0.0399, G Loss: 7.2155, Time:19:21:42\n",
            "Epoch: 1666/2200, Step: 15000, D Loss: 0.0026, G Loss: 7.3799, Time:19:23:12\n",
            "Epoch: 1722/2200, Step: 15500, D Loss: 0.0012, G Loss: 7.8502, Time:19:24:44\n",
            "Epoch: 1777/2200, Step: 16000, D Loss: 0.0003, G Loss: 8.3804, Time:19:26:15\n",
            "Epoch: 1833/2200, Step: 16500, D Loss: 0.0094, G Loss: 6.8747, Time:19:27:45\n",
            "Epoch: 1888/2200, Step: 17000, D Loss: 0.0161, G Loss: 5.0624, Time:19:29:14\n",
            "Epoch: 1944/2200, Step: 17500, D Loss: 0.0374, G Loss: 9.2554, Time:19:30:44\n",
            "Epoch: 2000/2200, Step: 18000, D Loss: 0.0649, G Loss: 4.4716, Time:19:32:13\n",
            "Epoch: 2055/2200, Step: 18500, D Loss: 0.0349, G Loss: 4.9111, Time:19:33:42\n",
            "Epoch: 2111/2200, Step: 19000, D Loss: 0.0030, G Loss: 8.3210, Time:19:35:11\n",
            "Epoch: 2166/2200, Step: 19500, D Loss: 0.0088, G Loss: 7.4077, Time:19:36:40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xM5yzGXvm_B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "021116fa-7759-4b63-e9d6-d94aa2957448"
      },
      "source": [
        "# generation to image\n",
        "G.eval()\n",
        "imshow(get_sample_image(G, n_noise)[0])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0d207eaf98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SE_fT2yHvo4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Real Image\n",
        "#t = Image.open(dataset.fpaths[999])\n",
        "#t = (transform(t).permute(1, 2, 0)+1)/2.\n",
        "#imshow(t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmGzqH6kvrCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(state, file_name='checkpoint.pth.tar'):\n",
        "    torch.save(state, file_name)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gMzQXcnvs5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Saving params.\n",
        "# torch.save(D.state_dict(), 'D_c.pkl')\n",
        "# torch.save(G.state_dict(), 'G_c.pkl')\n",
        "save_checkpoint({'epoch': epoch + 1,\n",
        "                 'D':D.state_dict(),\n",
        "                 'G':G.state_dict(),\n",
        "                 'd_optim': D_opt.state_dict(),\n",
        "                 'g_optim' : G_opt.state_dict()},\n",
        "                'dcgan.pth.tar')"
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}