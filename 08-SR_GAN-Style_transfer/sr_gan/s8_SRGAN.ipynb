{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "s8_SRGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1ay7x_mdZkoj2_S81_0R3L2VWM8BDf6dX",
      "authorship_tag": "ABX9TyPdQ+0HZMQctDthn2XAfA/C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8abd23670ff54ee5b341fac4eac81f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53738fbae6a4446690eb435f2149a14f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d0eceadea3e4c9caabb374e159d713f",
              "IPY_MODEL_aaea7a9017a54a3589a6cf6e0e048f1d"
            ]
          }
        },
        "53738fbae6a4446690eb435f2149a14f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d0eceadea3e4c9caabb374e159d713f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4e6c6f28d85b47c791d78960dfce0712",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c497d634085f423eba7020ab9f3adc68"
          }
        },
        "aaea7a9017a54a3589a6cf6e0e048f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b47c9f3a7604131b3dbe0317f91fb38",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [02:26&lt;00:00, 3.79MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b8a7e5561c944d3995dd74d942c9e5ac"
          }
        },
        "4e6c6f28d85b47c791d78960dfce0712": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c497d634085f423eba7020ab9f3adc68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b47c9f3a7604131b3dbe0317f91fb38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b8a7e5561c944d3995dd74d942c9e5ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chirag2saraiya/TSAI-DeepVision-EVA4/blob/master/08-SR_GAN-Style_transfer/sr_gan/s8_SRGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De9WrMYNcusj",
        "outputId": "22f80bdc-3fcf-4bd2-e1ba-5880ec6f1b92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "# Downgrade pytorch and torchvision to get models compatible with aws deployment\n",
        "!pip install torch==1.5.1+cu92 torchvision==0.6.1+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torch-1.5.1%2Bcu92-cp36-cp36m-linux_x86_64.whl (604.8MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 604.8MB 24kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.6.1%2Bcu92-cp36-cp36m-linux_x86_64.whl (6.5MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.5MB 29.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu92) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu92) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu92) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu92 torchvision-0.6.1+cu92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSaHpo5WRGlD",
        "outputId": "4ceb3b01-7b1e-4be1-d8a9-6d2886a89088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "!git clone https://github.com/GauravPatel89/SRGAN.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SRGAN'...\n",
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 1060 (delta 4), reused 0 (delta 0), pack-reused 1049\u001b[K\n",
            "Receiving objects: 100% (1060/1060), 32.17 MiB | 40.42 MiB/s, done.\n",
            "Resolving deltas: 100% (671/671), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5c3rI2punIM",
        "outputId": "2588b877-511a-4393-e6ac-bea7f1cf9774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "!gdown --id 1QLhi8XYiezoBliCgLB3k6Chxsc8aXs3n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QLhi8XYiezoBliCgLB3k6Chxsc8aXs3n\n",
            "To: /content/Session2_Dataset_cleaned_resized.zip\n",
            "457MB [00:05, 85.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_iT8Cj1uv8D"
      },
      "source": [
        "!unzip -q Session2_Dataset_cleaned_resized.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjNcMiWvpLco"
      },
      "source": [
        "!rm -r /content/Session2_Dataset_cleaned_resized/Flying\\ Birds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmYoVlePjr3O",
        "outputId": "7d6f8e62-4f23-4524-ebb3-dbf1d2f06435",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/4b/7b282b0f9319189d71e803220748929b37d019b67b1782d14c59cb1bd940/split_folders-0.4.2-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HzAtiHfkLHY"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ_5REAvj0uh",
        "outputId": "845ce92c-74f7-45b7-c229-e6fa7b7fb32f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio(input = \"/content/Session2_Dataset_cleaned_resized\", output=\"/content/data\", seed=1337, ratio=(.998, .002), group_prefix=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying files: 12474 files [00:02, 6120.70 files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbm-NZ8wp5JM"
      },
      "source": [
        "!mkdir /content/SRGAN/data/train\n",
        "!mkdir /content/SRGAN/data/val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekoH26HFkZHi"
      },
      "source": [
        "!mv /content/data/train/Large\\ QuadCopters/*.jpg /content/SRGAN/data/train/\n",
        "!mv /content/data/val/Large\\ QuadCopters/*.jpg /content/SRGAN/data/val/\n",
        "!mv /content/data/train/Small\\ QuadCopters/*.jpg /content/SRGAN/data/train/\n",
        "!mv /content/data/val/Small\\ QuadCopters/*.jpg /content/SRGAN/data/val/\n",
        "!mv /content/data/train/Winged\\ Drones/*.jpg /content/SRGAN/data/train/\n",
        "!mv /content/data/val/Winged\\ Drones/*.jpg /content/SRGAN/data/val/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gkvn46k8dZfD",
        "outputId": "dd392de2-e8a3-49dc-c114-2523f1bf5068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd SRGAN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SRGAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-WzRhD3g4h4",
        "outputId": "2bd88318-29bc-41af-817a-a1a35f8973de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "from math import log10\n",
        "\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.utils as utils\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pytorch_ssim\n",
        "from data_utils import TrainDatasetFromFolder, ValDatasetFromFolder, display_transform\n",
        "from loss import GeneratorLoss\n",
        "from model import Generator, Discriminator"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e4b56470ece3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytorch_ssim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainDatasetFromFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValDatasetFromFolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGeneratorLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytorch_ssim'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEYXIDu4hEB_"
      },
      "source": [
        "CROP_SIZE = 88\n",
        "UPSCALE_FACTOR = 4\n",
        "NUM_EPOCHS = 50\n",
        "TRAIN_DATA_DIR = 'data/train'\n",
        "VAL_DATA_DIR = 'data/val'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV9BUrQnq81c"
      },
      "source": [
        "train_set = TrainDatasetFromFolder(TRAIN_DATA_DIR, crop_size=CROP_SIZE, upscale_factor=UPSCALE_FACTOR)\n",
        "val_set = ValDatasetFromFolder(VAL_DATA_DIR, upscale_factor=UPSCALE_FACTOR)\n",
        "train_loader = DataLoader(dataset=train_set, num_workers=4, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(dataset=val_set, num_workers=4, batch_size=1, shuffle=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0Zuv8LN2lV-",
        "outputId": "f8851b0c-923e-4cd1-eda0-fee03c13fc63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(len(train_set))\n",
        "print(len(val_set))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4698\n",
            "18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LKOspvzrDr6"
      },
      "source": [
        "testbatch = next(iter(train_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFjybe_kr98J",
        "outputId": "bc9ed9de-1a9f-43a8-cba2-bc143cc1f26e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(testbatch[0].shape)\n",
        "print(testbatch[1].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 3, 22, 22])\n",
            "torch.Size([64, 3, 88, 88])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onMOX13VsibU",
        "outputId": "62d00e2b-201b-4dc4-8dcd-eb3bac9ea237",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "netG = Generator(UPSCALE_FACTOR)\n",
        "print('# generator parameters:', sum(param.numel() for param in netG.parameters()))\n",
        "netD = Discriminator()\n",
        "print('# discriminator parameters:', sum(param.numel() for param in netD.parameters()))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# generator parameters: 734219\n",
            "# discriminator parameters: 5215425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5rsTBr4sj65",
        "outputId": "1a03ac8c-bafc-4d5e-bc6e-12e4fee919ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(netG, (3, 22, 22))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-22bd93b18c22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/SRGAN/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mblock1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mblock2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mblock3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 416\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orGTYI6Rs6Ww"
      },
      "source": [
        "summary(netD, (3, 88, 88))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9q2U042tHwT",
        "outputId": "61cd5b71-96ce-477f-b0ad-71eeec36c2eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "8abd23670ff54ee5b341fac4eac81f23",
            "53738fbae6a4446690eb435f2149a14f",
            "3d0eceadea3e4c9caabb374e159d713f",
            "aaea7a9017a54a3589a6cf6e0e048f1d",
            "4e6c6f28d85b47c791d78960dfce0712",
            "c497d634085f423eba7020ab9f3adc68",
            "9b47c9f3a7604131b3dbe0317f91fb38",
            "b8a7e5561c944d3995dd74d942c9e5ac"
          ]
        }
      },
      "source": [
        "generator_criterion = GeneratorLoss()\n",
        "if torch.cuda.is_available():\n",
        "    netG.cuda()\n",
        "    netD.cuda()\n",
        "    generator_criterion.cuda()\n",
        "\n",
        "optimizerG = optim.Adam(netG.parameters())\n",
        "optimizerD = optim.Adam(netD.parameters())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8abd23670ff54ee5b341fac4eac81f23",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Zqrygv6glke",
        "outputId": "e8ee27ff-2401-4bed-f9d7-85100cd16d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': [], 'ssim': []}\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train_bar = tqdm(train_loader)\n",
        "    running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
        "\n",
        "    netG.train()\n",
        "    netD.train()\n",
        "    for data, target in train_bar:\n",
        "        g_update_first = True\n",
        "        batch_size = data.size(0)\n",
        "        running_results['batch_sizes'] += batch_size\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize D(x)-1-D(G(z))\n",
        "        ###########################\n",
        "        real_img = Variable(target)\n",
        "        if torch.cuda.is_available():\n",
        "            real_img = real_img.cuda()\n",
        "        z = Variable(data)\n",
        "        if torch.cuda.is_available():\n",
        "            z = z.cuda()\n",
        "        fake_img = netG(z)\n",
        "\n",
        "        netD.zero_grad()\n",
        "        real_out = netD(real_img).mean()\n",
        "        fake_out = netD(fake_img).mean()\n",
        "        d_loss = 1 - real_out + fake_out\n",
        "        d_loss.backward(retain_graph=True)\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: minimize 1-D(G(z)) + Perception Loss + Image Loss + TV Loss\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        ############################################################\n",
        "        ## The two lines below are added to prevent runetime error! ##\n",
        "        fake_img = netG(z)\n",
        "        fake_out = netD(fake_img).mean()            \n",
        "        ###########################################################\n",
        "            \n",
        "        g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
        "        g_loss.backward()\n",
        "        \n",
        "        fake_img = netG(z)\n",
        "        fake_out = netD(fake_img).mean()\n",
        "        \n",
        "        \n",
        "        optimizerG.step()\n",
        "\n",
        "        # loss for current batch before optimization \n",
        "        running_results['g_loss'] += g_loss.item() * batch_size\n",
        "        running_results['d_loss'] += d_loss.item() * batch_size\n",
        "        running_results['d_score'] += real_out.item() * batch_size\n",
        "        running_results['g_score'] += fake_out.item() * batch_size\n",
        "\n",
        "        train_bar.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' % (\n",
        "            epoch, NUM_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n",
        "            running_results['g_loss'] / running_results['batch_sizes'],\n",
        "            running_results['d_score'] / running_results['batch_sizes'],\n",
        "            running_results['g_score'] / running_results['batch_sizes']))\n",
        "\n",
        "    netG.eval()\n",
        "    out_path = '/content/drive/My Drive/e4p2s8/trainingResults2/SRF_' + str(UPSCALE_FACTOR) + '/'\n",
        "    if not os.path.exists(out_path):\n",
        "        os.makedirs(out_path)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        val_bar = tqdm(val_loader)\n",
        "        valing_results = {'mse': 0, 'ssims': 0, 'psnr': 0, 'ssim': 0, 'batch_sizes': 0}\n",
        "        val_images = []\n",
        "        # val data_loader returns low_res, hr_restored(hr->lr->hr bicubic),original_hr images\n",
        "        for val_lr, val_hr_restore, val_hr in val_bar:\n",
        "            batch_size = val_lr.size(0)\n",
        "            valing_results['batch_sizes'] += batch_size\n",
        "            lr = val_lr\n",
        "            hr = val_hr\n",
        "            if torch.cuda.is_available():\n",
        "                lr = lr.cuda()\n",
        "                hr = hr.cuda()\n",
        "            sr = netG(lr)\n",
        "    \n",
        "            batch_mse = ((sr - hr) ** 2).data.mean()\n",
        "            valing_results['mse'] += batch_mse * batch_size\n",
        "            batch_ssim = pytorch_ssim.ssim(sr, hr).item()\n",
        "            valing_results['ssims'] += batch_ssim * batch_size\n",
        "            valing_results['psnr'] = 10 * log10((hr.max()**2) / (valing_results['mse'] / valing_results['batch_sizes']))\n",
        "            valing_results['ssim'] = valing_results['ssims'] / valing_results['batch_sizes']\n",
        "            val_bar.set_description(\n",
        "                desc='[converting LR images to SR images] PSNR: %.4f dB SSIM: %.4f' % (\n",
        "                    valing_results['psnr'], valing_results['ssim']))\n",
        "    \n",
        "            val_images.extend(\n",
        "                [display_transform()(val_hr_restore.squeeze(0)), display_transform()(hr.data.cpu().squeeze(0)),\n",
        "                  display_transform()(sr.data.cpu().squeeze(0))])\n",
        "        \n",
        "        val_images = torch.stack(val_images)\n",
        "        val_images = torch.chunk(val_images, val_images.size(0) // 15)\n",
        "        val_save_bar = tqdm(val_images, desc='[saving training results]')\n",
        "        index = 1\n",
        "        for image in val_save_bar:\n",
        "            image = utils.make_grid(image, nrow=3, padding=5)\n",
        "            utils.save_image(image, out_path + 'epoch_%d_index_%d.png' % (epoch, index), padding=5)\n",
        "            index += 1\n",
        "\n",
        "    # save model parameters\n",
        "    torch.save(netG.state_dict(), '/content/drive/My Drive/e4p2s8/trainingResults2/epochs/netG_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
        "    torch.save(netD.state_dict(), '/content/drive/My Drive/e4p2s8/trainingResults2/epochs/netD_epoch_%d_%d.pth' % (UPSCALE_FACTOR, epoch))\n",
        "    # save loss\\scores\\psnr\\ssim\n",
        "    results['d_loss'].append(running_results['d_loss'] / running_results['batch_sizes'])\n",
        "    results['g_loss'].append(running_results['g_loss'] / running_results['batch_sizes'])\n",
        "    results['d_score'].append(running_results['d_score'] / running_results['batch_sizes'])\n",
        "    results['g_score'].append(running_results['g_score'] / running_results['batch_sizes'])\n",
        "    results['psnr'].append(valing_results['psnr'])\n",
        "    results['ssim'].append(valing_results['ssim'])\n",
        "\n",
        "    if epoch % 10 == 0 and epoch != 0:\n",
        "        out_path = '/content/drive/My Drive/e4p2s8/trainingResults2/statistics/'\n",
        "        data_frame = pd.DataFrame(\n",
        "            data={'Loss_D': results['d_loss'], 'Loss_G': results['g_loss'], 'Score_D': results['d_score'],\n",
        "                  'Score_G': results['g_score'], 'PSNR': results['psnr'], 'SSIM': results['ssim']},\n",
        "            index=range(1, epoch + 1))\n",
        "        data_frame.to_csv(out_path + 'srf_' + str(UPSCALE_FACTOR) + '_train_results.csv', index_label='Epoch')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/50] Loss_D: 0.9694 Loss_G: 0.0187 D(x): 0.7377 D(G(z)): 0.7043: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.19it/s]\n",
            "[converting LR images to SR images] PSNR: 20.8865 dB SSIM: 0.7622: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.81it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.04it/s]\n",
            "[2/50] Loss_D: 0.9968 Loss_G: 0.0095 D(x): 0.7437 D(G(z)): 0.7421: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 22.4286 dB SSIM: 0.7924: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.01it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.02s/it]\n",
            "[3/50] Loss_D: 0.9978 Loss_G: 0.0079 D(x): 0.7287 D(G(z)): 0.7244: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 24.9717 dB SSIM: 0.8283: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.88it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.03it/s]\n",
            "[4/50] Loss_D: 1.0019 Loss_G: 0.0069 D(x): 0.7095 D(G(z)): 0.7099: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.20it/s]\n",
            "[converting LR images to SR images] PSNR: 23.0438 dB SSIM: 0.8236: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.46it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.05it/s]\n",
            "[5/50] Loss_D: 0.9991 Loss_G: 0.0066 D(x): 0.6581 D(G(z)): 0.6561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.20it/s]\n",
            "[converting LR images to SR images] PSNR: 24.3050 dB SSIM: 0.8368: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.86it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.06it/s]\n",
            "[6/50] Loss_D: 1.0045 Loss_G: 0.0058 D(x): 0.6580 D(G(z)): 0.6612: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.20it/s]\n",
            "[converting LR images to SR images] PSNR: 25.9896 dB SSIM: 0.8482: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 16.33it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.01s/it]\n",
            "[7/50] Loss_D: 1.0007 Loss_G: 0.0055 D(x): 0.6724 D(G(z)): 0.6720: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 25.0335 dB SSIM: 0.8471: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.36it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.04it/s]\n",
            "[8/50] Loss_D: 1.0001 Loss_G: 0.0055 D(x): 0.3945 D(G(z)): 0.3834: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 25.4671 dB SSIM: 0.8506: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.75it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.03it/s]\n",
            "[9/50] Loss_D: 1.0000 Loss_G: 0.0060 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.20it/s]\n",
            "[converting LR images to SR images] PSNR: 26.5009 dB SSIM: 0.8580: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.37it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.07it/s]\n",
            "[10/50] Loss_D: 1.0000 Loss_G: 0.0057 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 26.6934 dB SSIM: 0.8606: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.98it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.06it/s]\n",
            "[11/50] Loss_D: 1.0000 Loss_G: 0.0054 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 25.2875 dB SSIM: 0.8565: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.96it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.04it/s]\n",
            "[12/50] Loss_D: 1.0000 Loss_G: 0.0055 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 25.5583 dB SSIM: 0.8551: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.03it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.11it/s]\n",
            "[13/50] Loss_D: 1.0000 Loss_G: 0.0054 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.20it/s]\n",
            "[converting LR images to SR images] PSNR: 25.6772 dB SSIM: 0.8561: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.84it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.04it/s]\n",
            "[14/50] Loss_D: 1.0000 Loss_G: 0.0055 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.22it/s]\n",
            "[converting LR images to SR images] PSNR: 26.7983 dB SSIM: 0.8595: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.13it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.04it/s]\n",
            "[15/50] Loss_D: 1.0000 Loss_G: 0.0055 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 26.8656 dB SSIM: 0.8623: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.96it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.06it/s]\n",
            "[16/50] Loss_D: 1.0000 Loss_G: 0.0052 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 26.4774 dB SSIM: 0.8669: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.83it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.05it/s]\n",
            "[17/50] Loss_D: 1.0000 Loss_G: 0.0050 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.20it/s]\n",
            "[converting LR images to SR images] PSNR: 23.6738 dB SSIM: 0.8553: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.10it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.12it/s]\n",
            "[18/50] Loss_D: 1.0000 Loss_G: 0.0057 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 26.8065 dB SSIM: 0.8605: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.22it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.07it/s]\n",
            "[19/50] Loss_D: 1.0000 Loss_G: 0.0049 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 26.9931 dB SSIM: 0.8672: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.81it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.06it/s]\n",
            "[20/50] Loss_D: 1.0000 Loss_G: 0.0051 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.22it/s]\n",
            "[converting LR images to SR images] PSNR: 26.7227 dB SSIM: 0.8660: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.89it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.05it/s]\n",
            "[21/50] Loss_D: 1.0000 Loss_G: 0.0049 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.22it/s]\n",
            "[converting LR images to SR images] PSNR: 27.1984 dB SSIM: 0.8671: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.04it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.06it/s]\n",
            "[22/50] Loss_D: 1.0000 Loss_G: 0.0049 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 26.2823 dB SSIM: 0.8640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.05it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.05it/s]\n",
            "[23/50] Loss_D: 1.0000 Loss_G: 0.0048 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 25.8749 dB SSIM: 0.8636: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.60it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.10it/s]\n",
            "[24/50] Loss_D: 1.0000 Loss_G: 0.0049 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.20it/s]\n",
            "[converting LR images to SR images] PSNR: 27.1559 dB SSIM: 0.8698: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.19it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.08it/s]\n",
            "[25/50] Loss_D: 1.0000 Loss_G: 0.0049 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 25.7961 dB SSIM: 0.8663: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.10it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.07it/s]\n",
            "[26/50] Loss_D: 1.0000 Loss_G: 0.0049 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 25.6164 dB SSIM: 0.8653: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.94it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.10it/s]\n",
            "[27/50] Loss_D: 1.0000 Loss_G: 0.0048 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 25.4391 dB SSIM: 0.8667: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.15it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.08it/s]\n",
            "[28/50] Loss_D: 1.0000 Loss_G: 0.0046 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 26.3200 dB SSIM: 0.8668: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.11it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.11it/s]\n",
            "[29/50] Loss_D: 1.0000 Loss_G: 0.0046 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 27.3780 dB SSIM: 0.8716: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.22it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.10it/s]\n",
            "[30/50] Loss_D: 1.0000 Loss_G: 0.0046 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.22it/s]\n",
            "[converting LR images to SR images] PSNR: 26.7506 dB SSIM: 0.8693: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.91it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.08it/s]\n",
            "[31/50] Loss_D: 1.0000 Loss_G: 0.0046 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 26.6236 dB SSIM: 0.8692: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.51it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.07it/s]\n",
            "[32/50] Loss_D: 1.0000 Loss_G: 0.0047 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 26.1995 dB SSIM: 0.8647: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.40it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.09it/s]\n",
            "[33/50] Loss_D: 1.0000 Loss_G: 0.0046 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 27.4088 dB SSIM: 0.8725: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.52it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.09it/s]\n",
            "[34/50] Loss_D: 1.0000 Loss_G: 0.0045 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 26.8946 dB SSIM: 0.8665: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.70it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.10it/s]\n",
            "[35/50] Loss_D: 1.0000 Loss_G: 0.0045 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 26.5462 dB SSIM: 0.8715: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.98it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.10it/s]\n",
            "[36/50] Loss_D: 1.0000 Loss_G: 0.0045 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 27.5276 dB SSIM: 0.8721: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.04it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.08it/s]\n",
            "[37/50] Loss_D: 1.0000 Loss_G: 0.0044 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 27.5413 dB SSIM: 0.8730: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.28it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.09it/s]\n",
            "[38/50] Loss_D: 1.0000 Loss_G: 0.0045 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.22it/s]\n",
            "[converting LR images to SR images] PSNR: 27.4030 dB SSIM: 0.8703: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.58it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.08it/s]\n",
            "[39/50] Loss_D: 1.0000 Loss_G: 0.0043 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 27.0704 dB SSIM: 0.8740: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.77it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.11it/s]\n",
            "[40/50] Loss_D: 1.0000 Loss_G: 0.0044 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 26.2666 dB SSIM: 0.8670: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.93it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.09it/s]\n",
            "[41/50] Loss_D: 1.0000 Loss_G: 0.0045 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 27.1765 dB SSIM: 0.8724: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.45it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.10it/s]\n",
            "[42/50] Loss_D: 1.0000 Loss_G: 0.0044 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.20it/s]\n",
            "[converting LR images to SR images] PSNR: 27.7187 dB SSIM: 0.8739: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.36it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.12it/s]\n",
            "[43/50] Loss_D: 1.0000 Loss_G: 0.0046 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.22it/s]\n",
            "[converting LR images to SR images] PSNR: 25.4722 dB SSIM: 0.8690: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.43it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.07it/s]\n",
            "[44/50] Loss_D: 1.0000 Loss_G: 0.0046 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.22it/s]\n",
            "[converting LR images to SR images] PSNR: 27.6665 dB SSIM: 0.8735: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.04it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.10it/s]\n",
            "[45/50] Loss_D: 1.0000 Loss_G: 0.0043 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 27.4481 dB SSIM: 0.8739: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.62it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.09it/s]\n",
            "[46/50] Loss_D: 1.0000 Loss_G: 0.0043 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 27.3163 dB SSIM: 0.8740: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.70it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.11it/s]\n",
            "[47/50] Loss_D: 1.0000 Loss_G: 0.0042 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 27.8757 dB SSIM: 0.8754: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.49it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.10it/s]\n",
            "[48/50] Loss_D: 1.0000 Loss_G: 0.0042 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 27.6101 dB SSIM: 0.8734: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.67it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.11it/s]\n",
            "[49/50] Loss_D: 1.0000 Loss_G: 0.0042 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 27.5905 dB SSIM: 0.8753: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:00<00:00, 18.07it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.10it/s]\n",
            "[50/50] Loss_D: 1.0000 Loss_G: 0.0042 D(x): 0.0000 D(G(z)): 0.0000: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:33<00:00,  2.21it/s]\n",
            "[converting LR images to SR images] PSNR: 27.2617 dB SSIM: 0.8752: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18/18 [00:01<00:00, 17.69it/s]\n",
            "[saving training results]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.12it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvNJ3r5QSnLv"
      },
      "source": [
        "!cp -r /content/SRGAN/epochs /content/drive/My\\ Drive/e4p2s8/trainingResults"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GO7HyaChfxLC"
      },
      "source": [
        "## Model Testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLC-kCNzCdNj"
      },
      "source": [
        "%cp /content/SRGAN/model.py ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I7BIBszfwdY"
      },
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.autograd import Variable\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "\n",
        "from model import Generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkQ8QD3Qft7J",
        "outputId": "a1efa4cf-9a0e-4b5c-e0f4-47a564b2a51e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\n",
        "UPSCALE_FACTOR = 4\n",
        "TEST_MODE = False \n",
        "IMAGE_NAME = 'test.jpeg'\n",
        "MODEL_NAME = '/content/drive/My Drive/e4p2s8/trainingResults2/epochs/netG_epoch_4_50.pth'\n",
        "\n",
        "model = Generator(UPSCALE_FACTOR).eval()\n",
        "if TEST_MODE:\n",
        "    model.cuda()\n",
        "    model.load_state_dict(torch.load(MODEL_NAME))\n",
        "else:\n",
        "    model.load_state_dict(torch.load(MODEL_NAME, map_location=lambda storage, loc: storage))\n",
        "\n",
        "image = Image.open(IMAGE_NAME)\n",
        "image = (ToTensor()(image)).unsqueeze(0)\n",
        "print(image.shape)\n",
        "if TEST_MODE:\n",
        "    image = image.cuda()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 183, 276])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAXDGToNgkei",
        "outputId": "196fc76e-6293-4462-e1f3-f356bbf269fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "start = time.clock()\n",
        "out = model(image)\n",
        "print(out.shape)\n",
        "elapsed = (time.clock() - start)\n",
        "out_img = ToPILImage()(out[0].data.cpu())\n",
        "out_img.save('out_srf_' + str(UPSCALE_FACTOR) + '_' + IMAGE_NAME.split('/')[-1])\n",
        "stop = time.clock()\n",
        "print('time: ',(stop-start),' Secs')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 732, 1104])\n",
            "time:  13.877126  Secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke9qvEGrhwAE"
      },
      "source": [
        "traced_model = torch.jit.trace(model,torch.randn(1,3,22,22))\n",
        "torch.jit.save(traced_model,'srgan_generator_JIT.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iplmslRRGth"
      },
      "source": [
        "torch.save(model.state_dict(),'srgan_generator_weights.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}